{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fbrecinos/TAC459_Final_Project/blob/main/TAC459_Final_Project10_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8glDo-4Tf8C"
      },
      "source": [
        "# TAC459 Final Project #10: Personal Shopping Recommender (via Google/Amazon Retail APIs)\n",
        "Group D: Elise Hadidi, Sama Shah, Nathan Chun, Varun Venkataraman, Faith Garcia, Aryan Halen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyLrj3W-UgZo"
      },
      "source": [
        "Project Structure:\n",
        "- Individual py files are created with %%writefile function_name.py -> When these cells are run, the py files will appear in the colab files/content tab\n",
        "- Streamlit App then uses these py files which are included by importing\n",
        "\n",
        "\n",
        "Assignments:\n",
        "- Nathan: api fetching, ranking\n",
        "- Aryan: explanation and UI\n",
        "\n",
        "Note: To run Streamlit in Colab, we need to use Cloudflare (has free version).  This is because Colab runs on a Google server, not your local machine.  Colab will block port access, so Cloudflare is needed to \"tunnel\" and allow access to the Streamlit App."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbqMSqDKUYb7",
        "outputId": "984665b1-fa09-4533-84e3-b16a6549bba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api_fetch.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile api_fetch.py\n",
        "\"\"\"\n",
        "api_fetch.py\n",
        "\n",
        "Module for fetching product data from Amazon via SerpApi.\n",
        "It also normalizes user queries and caches responses locally so we\n",
        "don't hit the API on every search.\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download NLTK stopwords to normalize user queries for cache keys.\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set of common English stopwords to remove from queries.\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# SerpApi key for Amazon search requests.\n",
        "API_KEY = "\n",
        "\n",
        "# JSON file used to cache previous query results and reduce API calls.\n",
        "CACHE_FILE = \"search_cache.json\"\n",
        "\n",
        "\n",
        "# Normalize raw user query text into a stable cache key\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Steps:\n",
        "    - Lowercase the text\n",
        "    - Remove URLs, @mentions, hashtags, and punctuation\n",
        "    - Remove common stopwords (e.g., \"the\", \"and\")\n",
        "    \"\"\"\n",
        "    # Make everything lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "\n",
        "    # Remove @usernames and hashtags\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Fetch products from Amazon using SerpApi with basic result caching\n",
        "def fetch_products(query):\n",
        "    \"\"\"\n",
        "    Workflow:\n",
        "    1. Load cached search results from local JSON file if it exists.\n",
        "    2. Normalize the user query with clean_text and use it as the cache key.\n",
        "    3. If we already have results for this key, return them immediately.\n",
        "    4. Otherwise, call the SerpApi Amazon engine, save the results to cache,\n",
        "       and return the list of products.\n",
        "    \"\"\"\n",
        "    # Initialize an empty cache in memory.\n",
        "    cache = {}\n",
        "\n",
        "    # If a cache file exists, load it into the cache dict.\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        try:\n",
        "            with open(CACHE_FILE, 'r') as f:\n",
        "                cache = json.load(f)\n",
        "        except:\n",
        "            # If the cache file is corrupted or unreadable, start fresh.\n",
        "            cache = {}\n",
        "\n",
        "    # Normalize the user query so similar queries share the same cache key.\n",
        "    query_key = clean_text(query)\n",
        "\n",
        "    # If it's a normalized query, return cached results.\n",
        "    if query_key in cache:\n",
        "        print(f\"Found '{query}' in local cache.\")\n",
        "        return cache[query_key]\n",
        "\n",
        "    # If not in cache, call the live API.\n",
        "    print(f\"Fetching '{query}' from SerpApi...\")\n",
        "\n",
        "    try:\n",
        "        # SerpApi endpoint for general search.\n",
        "        url = \"https://serpapi.com/search.json\"\n",
        "\n",
        "        # Parameters specify the Amazon engine and search options.\n",
        "        params = {\n",
        "            \"engine\": \"amazon\",          # Use SerpApi's Amazon search engine\n",
        "            \"k\": query,                  # Raw user query sent to Amazon\n",
        "            \"api_key\": API_KEY,          # Authentication for SerpApi\n",
        "            \"num\": 10,                   # Number of results to fetch\n",
        "            \"amazon_domain\": \"amazon.com\",\n",
        "        }\n",
        "\n",
        "        # Make the HTTP GET request to SerpApi with a timeout for safety.\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "\n",
        "        # Convert the JSON response into a Python dict.\n",
        "        data = response.json()\n",
        "\n",
        "        # If the response has organic_results (normal search results with fields like title, price, link etc.), extract them.\n",
        "        if \"organic_results\" in data:\n",
        "            results = data[\"organic_results\"]\n",
        "\n",
        "            # Save the results in the cache under the normalized query key.\n",
        "            cache[query_key] = results\n",
        "            with open(CACHE_FILE, 'w') as f:\n",
        "                json.dump(cache, f, indent=4)\n",
        "\n",
        "            # Return the list of product dictionaries.\n",
        "            return results\n",
        "\n",
        "        # If SerpApi returned an explicit error message, log it and fail gracefully.\n",
        "        elif \"error\" in data:\n",
        "            print(\"API Error:\", data[\"error\"])\n",
        "            return []\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle network issues, timeouts, or any unexpected exceptions.\n",
        "        print(\"Connection Error:\", e)\n",
        "        return []\n",
        "\n",
        "    # Fallback: if nothing else returned, give back an empty list.\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR9NWTKpSuL6",
        "outputId": "3b03b29d-1c2f-4ef4-c839-2aaa46b883cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ranking.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ranking.py\n",
        "\"\"\"\n",
        "ranking.py\n",
        "\n",
        "This module ranks Amazon product results returned from SerpApi.\n",
        "It converts product metadata into text, computes TF-IDF similarity\n",
        "between the user query and each product, and then scores each item\n",
        "based on similarity, rating, price, and review count.\n",
        "\n",
        "The output is the Top 5 recommended products for the query.\n",
        "\"\"\"\n",
        "\n",
        "# import necessary libraries and packages\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "#adding for ec\n",
        "from textblob import TextBlob\n",
        "\n",
        "#adding for ec\n",
        "def calculate_sentiment(text):\n",
        "    \"\"\"\n",
        "    Returns a float -1.0 (negative) to 1.0 (positive).\n",
        "    Uses TextBlob to analyze the 'vibe' of the product description/title.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return 0.0\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity\n",
        "\n",
        "# Compute cosine similarity between the user's query and every product's TF-IDF vector.\n",
        "def similarity_score(query, vectorizer, tfidf_matrix):\n",
        "\n",
        "    query_vector = vectorizer.transform([query])  # Convert query to TF-IDF vector\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten() # use cosine similarity to find closest matches to query vector\n",
        "    return similarities\n",
        "\n",
        "# Convert a product dictionary into a flattened string of textual fields\n",
        "def product_to_text(product):\n",
        "    \"\"\"\n",
        "    TF-IDF works on text, so we need to merge product fields like title,\n",
        "    description, features, price, and metadata into one searchable text document.\n",
        "    \"\"\"\n",
        "    fields = []\n",
        "\n",
        "    # Iterate over all product fields and convert values to text.\n",
        "    for key, value in product.items():\n",
        "        if isinstance(value, str):\n",
        "            fields.append(value)\n",
        "        elif isinstance(value, (int, float)):\n",
        "            fields.append(str(value))\n",
        "        elif isinstance(value, list):\n",
        "            fields.extend([str(v) for v in value])      # Flatten lists\n",
        "        elif isinstance(value, dict):\n",
        "            fields.extend([str(v) for v in value.values()])  # Flatten nested dictionaries\n",
        "\n",
        "    return \" \".join(fields)\n",
        "\n",
        "# Score how well the product's price fits within the user's budget\n",
        "def price_score(price, budget):\n",
        "    \"\"\"\n",
        "    Score = 1.0 if under budget.\n",
        "    Score decreases linearly the further the price exceeds the budget.\n",
        "    If price is missing, treat it as 0 (not ideal but prevents model crashes).\n",
        "    \"\"\"\n",
        "    if price is None:\n",
        "        return 0\n",
        "    if price <= budget:\n",
        "        return 1.0  # Perfect score when within budget\n",
        "    else:\n",
        "        diff = price - budget\n",
        "        return max(0, 1 - (diff / budget))  # Linear penalty for going over budget\n",
        "\n",
        "# Normalize review count: more reviews = higher confidence in rating\n",
        "def review_score(review_count, max_reviews):\n",
        "    \"\"\"\n",
        "    Review counts are scaled relative to the most-reviewed product.\n",
        "    Helps distinguish a 4.7★ rating with 10k reviews from 4.7★ with 8 reviews.\n",
        "    \"\"\"\n",
        "    if max_reviews is None or max_reviews <= 0:\n",
        "        return 0.0 # No valid scale to normalize against → neutral score\n",
        "\n",
        "    if review_count is None or review_count <= 0:\n",
        "        return 0.0 # Product has no reviews → lowest confidence\n",
        "\n",
        "    return review_count / max_reviews # Normalize relative to the highest review count\n",
        "\n",
        "#  Convert product rating (0–5 stars) into a normalized score (0–1).\n",
        "def rating_score(r):\n",
        "    if r is None:\n",
        "        return 0\n",
        "    return r / 5.0\n",
        "\n",
        "\n",
        "def combined_score(sim, rating, price, review, sentiment):\n",
        "    \"\"\"\n",
        "    Weighted scoring function that combines:\n",
        "    - Text relevance (similarity)\n",
        "    - Rating quality\n",
        "    - Price fit vs budget\n",
        "    - Review confidence\n",
        "\n",
        "    Weights reflect what we see as important. Similarity is deemed strongest factor.\n",
        "    \"\"\"\n",
        "    W_SIM = 0.7   # Query relevance matters most\n",
        "    W_RAT = 0.4   # Higher rating improves trustworthiness\n",
        "    W_PRICE = 0.2 # Staying within budget matters but less than relevance\n",
        "    W_REV = 0.2   # Review count adds stability to the rating\n",
        "\n",
        "    W_SENT = 0.3 # Sentiment Weight\n",
        "    norm_sentiment = (sentiment + 1) / 2 # Normalize sentiment (-1 to 1) to (0 to 1) for scoring\n",
        "\n",
        "    return (W_SIM * sim) + (W_RAT * rating) + (W_PRICE * price) + (W_REV * review) + (W_SENT * norm_sentiment)\n",
        "\n",
        "\n",
        "def rank_products(products_list, query, budget=100):\n",
        "    \"\"\"\n",
        "    Main ranking pipeline:\n",
        "\n",
        "    1. Convert each product into a text document.\n",
        "    2. Build a TF-IDF model across all products.\n",
        "    3. Compute similarity scores vs the user query.\n",
        "    4. Extract pricing, rating, and review info for each product.\n",
        "    5. Compute a combined weighted score for ranking.\n",
        "    6. Sort results and return the top 10.\n",
        "\n",
        "    Returns: list of product dictionaries with scoring metadata added.\n",
        "    \"\"\"\n",
        "    if not products_list:\n",
        "        return []\n",
        "\n",
        "    # Convert products into TF-IDF-ready documents\n",
        "    documents = [product_to_text(p) for p in products_list]\n",
        "\n",
        "    # Create TF-IDF model and compute product vectors\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Compute text similarity\n",
        "    similarities = similarity_score(query, vectorizer, tfidf_matrix)\n",
        "\n",
        "    # Collect review counts to compute normalization base\n",
        "    review_counts = []\n",
        "    for p in products_list:\n",
        "        rc = (\n",
        "            p.get(\"ratings_total\") or\n",
        "            p.get(\"reviews\") or\n",
        "            p.get(\"review_count\") or\n",
        "            0\n",
        "        )\n",
        "        review_counts.append(rc if isinstance(rc, (int, float)) else 0)\n",
        "\n",
        "    max_reviews = max(review_counts) if review_counts else 0\n",
        "\n",
        "    ranked = []\n",
        "\n",
        "    # Score each product\n",
        "    for i, product in enumerate(products_list):\n",
        "\n",
        "        # Clean/parse price text like \"$149.99\"\n",
        "        raw_price = product.get(\"price\", \"0\")\n",
        "        if isinstance(raw_price, str):\n",
        "            price_clean = re.sub(r'[^\\d.]', '', raw_price)  # Keep only digits + decimals\n",
        "            try:\n",
        "                price = float(price_clean)\n",
        "            except ValueError:\n",
        "                price = 0.0\n",
        "        else:\n",
        "            price = float(raw_price) if raw_price else 0.0\n",
        "\n",
        "        rating = product.get(\"rating\", 0.0)\n",
        "        sim = float(similarities[i])\n",
        "\n",
        "        # Retrieve some version of review count depending on SerpApi format\n",
        "        raw_reviews = (\n",
        "            product.get(\"ratings_total\") or\n",
        "            product.get(\"reviews\") or\n",
        "            product.get(\"review_count\") or\n",
        "            0\n",
        "        )\n",
        "        review_count = raw_reviews if isinstance(raw_reviews, (int, float)) else 0\n",
        "\n",
        "        # adding for ec\n",
        "        text_content = f\"{product.get('title', '')} {product.get('snippet', '')}\"\n",
        "        sentiment_val = calculate_sentiment(text_content)\n",
        "\n",
        "        # Compute each scoring component\n",
        "        pr_score = price_score(price, budget)\n",
        "        rat_score = rating_score(rating)\n",
        "        rev_score = review_score(review_count, max_reviews)\n",
        "\n",
        "        # Final weighted score\n",
        "        final = combined_score(sim, rat_score, pr_score, rev_score, sentiment_val)\n",
        "\n",
        "        # Store scored product metadata\n",
        "        ranked.append({\n",
        "            \"asin\": product.get(\"asin\"),\n",
        "            \"title\": product.get(\"title\"),\n",
        "            \"price\": price,\n",
        "            \"rating\": rating,\n",
        "            \"similarity\": sim,\n",
        "            \"sentiment\": sentiment_val,\n",
        "            \"price_score\": pr_score,\n",
        "            \"rating_score\": rat_score,\n",
        "            \"review_count\": review_count,\n",
        "            \"review_score\": rev_score,\n",
        "            \"final_score\": final,\n",
        "            \"thumbnail\": product.get(\"thumbnail\"),\n",
        "            \"link\": product.get(\"link\")\n",
        "        })\n",
        "\n",
        "    # Sort results by, final_score (descending), rating (descending), price (ascending)\n",
        "    ranked = sorted(\n",
        "        ranked,\n",
        "        key=lambda x: (x[\"final_score\"], x[\"rating\"], -x[\"price\"]),\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Return Top 5 products\n",
        "    return ranked[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKWlTo-OVJ9o",
        "outputId": "34146945-9a7f-43a7-b994-619f968ef658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting explain.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile explain.py\n",
        "\"\"\"\n",
        "explain.py\n",
        "\n",
        "Handles the presentation layer of the recommender system.\n",
        "This module:\n",
        "- Generates human-readable explanations for each recommended product\n",
        "- Builds the “Pros / Cons” analysis based on scoring attributes\n",
        "- Displays product cards, images, pricing info, and badges in Streamlit\n",
        "- Supports a user profile with saved items for personalization\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# Construct a list of 'pros' and 'cons' explaining why this product was recommended\n",
        "def build_pros_cons(item, budget):\n",
        "\n",
        "    pros = []\n",
        "    cons = []\n",
        "\n",
        "    # Price fit analysis\n",
        "    if item[\"price_score\"] == 1.0:\n",
        "        pros.append(\"Under your budget.\") # Perfect fit\n",
        "    elif item[\"price_score\"] < 0.5:\n",
        "        cons.append(\"Noticeably above your budget.\") # Strong penalty\n",
        "\n",
        "    # Rating quality analysis\n",
        "    if item[\"rating\"] and item[\"rating\"] >= 4.5:\n",
        "        pros.append(\"High customer rating (4.5★ or higher).\")\n",
        "    elif item[\"rating\"] and item[\"rating\"] < 3.8:\n",
        "        cons.append(\"Lower rating than other options.\")\n",
        "\n",
        "    # Review count confidence\n",
        "    if item.get(\"review_count\", 0) > 0:\n",
        "        pros.append(f\"Based on {int(item['review_count'])}+ reviews.\")  # Rating is reliable\n",
        "    else:\n",
        "        cons.append(\"Few or no visible reviews.\") # Low confidence in rating\n",
        "\n",
        "    # Sentiment Explanation added for ec\n",
        "    if item.get(\"sentiment\", 0) > 0.3:\n",
        "        pros.append(\"Very positive product description/sentiment.\")\n",
        "    elif item.get(\"sentiment\", 0) < 0.0:\n",
        "        cons.append(\"Neutral or vague product description.\")\n",
        "\n",
        "    # Text relevance to user's query\n",
        "    if item[\"similarity\"] >= 0.7:\n",
        "        pros.append(\"Strong match to your search terms.\")  # High TF-IDF similarity\n",
        "    elif item[\"similarity\"] < 0.4:\n",
        "        cons.append(\"Weaker text match to your query.\") # Might not fully match intent\n",
        "\n",
        "    return pros, cons\n",
        "\n",
        "# Comparison Table Display\n",
        "def show_comparison_table(selected_items):\n",
        "    if not selected_items:\n",
        "        st.warning(\"No items selected for comparison.\")\n",
        "        return\n",
        "\n",
        "    st.subheader(\"Product Comparison\")\n",
        "\n",
        "    # Create a dictionary for the dataframe\n",
        "    data = {}\n",
        "    for item in selected_items:\n",
        "        short_title = item['title'][:30] + \"...\" if len(item['title']) > 30 else item['title']\n",
        "        data[short_title] = {\n",
        "            \"Price\": f\"${item['price']:.2f}\",\n",
        "            \"Rating\": f\"{item['rating']} ★\",\n",
        "            \"Reviews\": int(item['review_count']),\n",
        "            \"Sentiment Score\": f\"{item['sentiment']:.2f}\",\n",
        "            \"Match Score\": f\"{item['final_score']:.2f}\"\n",
        "        }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    st.table(df)\n",
        "\n",
        "# Display the ranked list of product recommendations in Streamlit\n",
        "def show_results(ranked_products, full_query, budget):\n",
        "    \"\"\"\n",
        "    For each recommended item:\n",
        "    - Show product image, title, price, rating, and badges\n",
        "    - Provide a link to Amazon\n",
        "    - Allow user to save items to their profile (“likes”)\n",
        "    - Show an explanation block with relevance, rating, price, and review confidence\n",
        "    \"\"\"\n",
        "    if not ranked_products:\n",
        "        st.warning(\"No products found matching your criteria.\")\n",
        "        return\n",
        "\n",
        "    # Initialize a persistent “profile” for saved items & personalization\n",
        "    if \"profile\" not in st.session_state:\n",
        "        st.session_state[\"profile\"] = {\n",
        "            \"likes\": [],\n",
        "            \"last_budget\": None,\n",
        "            \"favorite_brands\": [],\n",
        "            \"compare_list\": []\n",
        "        }\n",
        "\n",
        "    # Helper to update comparison list state\n",
        "    def update_compare(item, key):\n",
        "        if st.session_state[key]: # If checked\n",
        "            if item not in st.session_state[\"profile\"][\"compare_list\"]:\n",
        "                st.session_state[\"profile\"][\"compare_list\"].append(item)\n",
        "        else: # If unchecked\n",
        "            # Remove item based on ASIN/Title matching\n",
        "            st.session_state[\"profile\"][\"compare_list\"] = [\n",
        "                i for i in st.session_state[\"profile\"][\"compare_list\"]\n",
        "                if i['title'] != item['title']\n",
        "            ]\n",
        "\n",
        "    st.subheader(f\"Top {len(ranked_products)} Recommendations\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Show comparison buttons if items are selected\n",
        "    compare_count = len(st.session_state[\"profile\"][\"compare_list\"])\n",
        "    if compare_count > 0:\n",
        "        col_btn1, col_btn2 = st.columns([1, 1])\n",
        "        with col_btn1:\n",
        "            if st.button(f\"Compare {compare_count} Selected Items\"):\n",
        "                show_comparison_table(st.session_state[\"profile\"][\"compare_list\"])\n",
        "        with col_btn2:\n",
        "            if st.button(\"Clear Comparison Selection\"):\n",
        "                st.session_state[\"profile\"][\"compare_list\"] = []\n",
        "                st.rerun()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Iterate through ranked products and build the UI card for each one\n",
        "    for idx, item in enumerate(ranked_products):\n",
        "        with st.container():\n",
        "            # Split card layout: left = image, right = information\n",
        "            col1, col2 = st.columns([1, 3])\n",
        "\n",
        "            # LEFT COLUMN (Image)\n",
        "            with col1:\n",
        "                if item.get('thumbnail'):\n",
        "                    st.image(item['thumbnail'], use_container_width=True)\n",
        "                else:\n",
        "                    st.text(\"No Image\")\n",
        "\n",
        "            # RIGHT COLUMN (Details)\n",
        "            with col2:\n",
        "                st.markdown(f\"### {item['title']}\")  # Product title\n",
        "\n",
        "                # Badges reflecting strengths based on scoring\n",
        "                badges = []\n",
        "                if item['final_score'] > 0.7:\n",
        "                    badges.append(\"Highly Relevant\")\n",
        "                if item['rating'] and item['rating'] >= 4.5:\n",
        "                    badges.append(\"Top Rated\")\n",
        "                if item['price_score'] == 1.0:\n",
        "                    badges.append(\"Within Budget\")\n",
        "\n",
        "                if badges:\n",
        "                    st.markdown(\" \".join([f\"`{b}`\" for b in badges]))\n",
        "\n",
        "                # Price + Rating text\n",
        "                price_display = f\"${item['price']:.2f}\" if item['price'] > 0 else \"Price varies\"\n",
        "\n",
        "                if item.get(\"review_count\"):\n",
        "                    # Include estimated review count when available\n",
        "                    st.write(\n",
        "                        f\"**Price:** {price_display}  \\n\"\n",
        "                        f\"**Rating:** {item['rating']} (based on ~{int(item['review_count'])} reviews)\"\n",
        "                    )\n",
        "                else:\n",
        "                    st.write(f\"**Price:** {price_display}\")\n",
        "                    st.write(f\"**Rating:** {item['rating']}\")\n",
        "\n",
        "                # Amazon product link\n",
        "                if item.get('link'):\n",
        "                    st.markdown(f\"[View on Amazon]({item['link']})\")\n",
        "\n",
        "                # Save button for personalization\n",
        "                asin = item.get(\"asin\") or f\"idx-{idx}\"\n",
        "                if st.button(\"Save to profile\", key=f\"like-{asin}\"):\n",
        "                    likes = st.session_state[\"profile\"][\"likes\"]\n",
        "\n",
        "                    # Add only if it's not already saved\n",
        "                    if asin not in [p.get(\"asin\") for p in likes]:\n",
        "                        likes.append(item)\n",
        "                        st.success(\"Saved to your profile.\")\n",
        "\n",
        "                # Check if item is already in the list to maintain state on re-runs\n",
        "                is_selected = any(c['title'] == item['title'] for c in st.session_state[\"profile\"][\"compare_list\"])\n",
        "                st.checkbox(\n",
        "                    \"Select to Compare\",\n",
        "                    value=is_selected,\n",
        "                    key=f\"comp_{idx}\",\n",
        "                    on_change=update_compare,\n",
        "                    args=(item, f\"comp_{idx}\")\n",
        "                )\n",
        "\n",
        "                # Explanation panel with scoring breakdown\n",
        "                with st.expander(\" Why this product? (AI Score Breakdown)\"):\n",
        "                    st.progress(min(item['final_score'], 1.0), text=\"Match Score\")\n",
        "\n",
        "                    # Compact score display\n",
        "                    st.caption(\n",
        "                        f\"Relevance: {item['similarity']:.2f} | \"\n",
        "                        f\"Rating Score: {item['rating_score']:.2f} | \"\n",
        "                        f\"Price Score: {item['price_score']:.2f} | \"\n",
        "                        f\"Review Score: {item.get('review_score', 0):.2f}\"\n",
        "                    )\n",
        "\n",
        "                    # Build the natural-language pros/cons explanation\n",
        "                    pros, cons = build_pros_cons(item, budget)\n",
        "\n",
        "                    if pros:\n",
        "                        st.markdown(\"**Pros:**\")\n",
        "                        for p in pros:\n",
        "                            st.markdown(f\"- {p}\")\n",
        "\n",
        "                    if cons:\n",
        "                        st.markdown(\"**Cons / Trade-offs:**\")\n",
        "                        for c in cons:\n",
        "                            st.markdown(f\"- {c}\")\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "    # SIDEBAR: Saved items (“profile”)\n",
        "    likes = st.session_state[\"profile\"][\"likes\"]\n",
        "    if likes:\n",
        "        with st.sidebar:\n",
        "            st.markdown(\"### Saved Items\")\n",
        "            for p in likes:\n",
        "                # Truncate titles for neat appearance\n",
        "                st.write(f\"- {p['title'][:40]}{'…' if len(p['title']) > 40 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyl7Ruwyay6y"
      },
      "source": [
        "# Start of Streamlit App Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KzsLZULrNDRN",
        "outputId": "f58dc332-f711-4aaa-87b8-89b901f2fbf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Testing API Fetch\\n\\nimport importlib\\nimport api_fetch\\n# Reload to use newest version of api_fetch (cached old version may be used even after updating)\\nimportlib.reload(api_fetch)\\n\\nfrom api_fetch import fetch_products\\noptions = fetch_products(\"Find a noise-cancling headphone for under $150\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "'''\n",
        "# Testing API Fetch\n",
        "\n",
        "import importlib\n",
        "import api_fetch\n",
        "# Reload to use newest version of api_fetch (cached old version may be used even after updating)\n",
        "importlib.reload(api_fetch)\n",
        "\n",
        "from api_fetch import fetch_products\n",
        "options = fetch_products(\"Find a noise-cancling headphone for under $150\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "bFq7d-ROLOn_",
        "outputId": "fe97f52c-0169-473b-b59d-bf8446231053"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Testing Ranking\\n\\nimport ranking\\n# Reload to use newest version of ranking (cached old version may be used even after updating)\\nimportlib.reload(ranking)\\nfrom ranking import rank_products\\n\\nquery = \"Find a noise-cancling headphone for under $150\"\\ntop5options = rank_products(options, query)\\nprint(top5options)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "'''\n",
        "# Testing Ranking\n",
        "\n",
        "import ranking\n",
        "# Reload to use newest version of ranking (cached old version may be used even after updating)\n",
        "importlib.reload(ranking)\n",
        "from ranking import rank_products\n",
        "\n",
        "query = \"Find a noise-cancling headphone for under $150\"\n",
        "top5options = rank_products(options, query)\n",
        "print(top5options)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAZko8rha7xI",
        "outputId": "67ededa7-73ec-4072-f6a3-e5ac4d6d6f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\n",
        "app.py\n",
        "\n",
        "Main Streamlit application for the Personal Shopping Recommender.\n",
        "\n",
        "This file:\n",
        "- Collects the user’s search query, budget, brand preferences, and desired features\n",
        "- Builds a combined query string based on these inputs\n",
        "- Fetches product results from SerpApi using our API module\n",
        "- Ranks products using similarity, price fit, rating, and review count\n",
        "- Displays the recommendations with explanations via the UI module\n",
        "- Maintains a simple user profile (likes, previous budgets, favorite brands)\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/brown')\n",
        "except LookupError:\n",
        "    nltk.download('brown')\n",
        "\n",
        "# Internal modules for API access, ranking logic, and UI rendering\n",
        "from api_fetch import fetch_products\n",
        "from ranking import rank_products\n",
        "from explain import show_results\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit Page Configuration\n",
        "st.set_page_config(page_title=\"Personal Shopping Recommender\", layout=\"centered\")\n",
        "\n",
        "st.title(\"Personal Shopping Recommender\")\n",
        "\n",
        "# Intro description shown at top of UI\n",
        "st.markdown(\"\"\"\n",
        "Welcome! This app uses SerpApi to find Amazon products and creates a\n",
        "custom ranking based on your query similarity, budget, and ratings.\n",
        "\"\"\")\n",
        "\n",
        "### Persistent User Profile Setup\n",
        "\n",
        "# We store small amounts of user data (likes, budget, brands) between interactions.\n",
        "if \"profile\" not in st.session_state:\n",
        "    st.session_state[\"profile\"] = {\n",
        "        \"likes\": [],             # Products the user manually saves\n",
        "        \"last_budget\": None,     # Used to pre-fill the budget box\n",
        "        \"favorite_brands\": [],   # Brands the user has shown preference for\n",
        "        \"compare_list\": []       # Store items for comparison\n",
        "    }\n",
        "\n",
        "# We also need to store the search results so they persist when buttons are clicked\n",
        "if \"search_results\" not in st.session_state:\n",
        "    st.session_state[\"search_results\"] = None\n",
        "if \"current_query\" not in st.session_state:\n",
        "    st.session_state[\"current_query\"] = \"\"\n",
        "\n",
        "# Easier reference to the profile\n",
        "profile = st.session_state[\"profile\"]\n",
        "\n",
        "\n",
        "### User Input Fields\n",
        "\n",
        "# User’s natural-language search query\n",
        "query = st.text_input(\"Search for a product\", value=st.session_state[\"current_query\"])\n",
        "\n",
        "# Budget input with previous value auto-filled\n",
        "budget = st.number_input(\n",
        "    \"Budget\",\n",
        "    value=float(profile[\"last_budget\"] or 0.0),\n",
        "    step=10.0)\n",
        "\n",
        "# Brand preferences, tracked over multiple searches\n",
        "brand_pref = st.text_input(\n",
        "    \"Preferred brands (comma-separated)\",\n",
        "    value=\", \".join(profile[\"favorite_brands\"])\n",
        ")\n",
        "\n",
        "# Additional feature filters the user cares about\n",
        "features = st.text_input(\"Must-have features (e.g., wireless, noise canceling, waterproof)\")\n",
        "\n",
        "\n",
        "# Search Button Interaction\n",
        "if st.button(\"Search\"):\n",
        "    st.write(\"Fetching results ...\")\n",
        "\n",
        "    ### Build the full expanded query string\n",
        "\n",
        "    # We merge the base query + brand preferences + features into one text query.\n",
        "    full_query_parts = [query]\n",
        "    if brand_pref:\n",
        "        full_query_parts.append(brand_pref)\n",
        "    if features:\n",
        "        full_query_parts.append(features)\n",
        "\n",
        "    full_query = \" \".join(full_query_parts)   # Combined query passed to SerpApi + TF-IDF model\n",
        "\n",
        "\n",
        "    # Update the user's profile\n",
        "    profile[\"last_budget\"] = budget\n",
        "\n",
        "    # Save new brands to user preferences\n",
        "    if brand_pref:\n",
        "        brands = [b.strip() for b in brand_pref.split(\",\") if b.strip()]\n",
        "        for b in brands:\n",
        "            if b not in profile[\"favorite_brands\"]:\n",
        "                profile[\"favorite_brands\"].append(b)\n",
        "\n",
        "    # Fetch products from SerpApi\n",
        "    raw_products = fetch_products(full_query)\n",
        "\n",
        "    if not raw_products:\n",
        "      st.session_state[\"search_results\"] = []\n",
        "      st.write(\"No products found.\")\n",
        "    else:\n",
        "        # Rank products using our scoring model\n",
        "        top_picks = rank_products(raw_products, full_query, budget)\n",
        "        st.session_state[\"search_results\"] = top_picks\n",
        "\n",
        "        # Display results using UI component\n",
        "if st.session_state[\"search_results\"]:\n",
        "    full_query_display = st.session_state[\"current_query\"]\n",
        "    show_results(st.session_state[\"search_results\"], full_query_display, budget)\n",
        "elif st.session_state[\"search_results\"] == []:\n",
        "    st.write(\"No results to display.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5bpzuirbt3I",
        "outputId": "9a172985-1602-4001-dd12-7baa8d461c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-12-12T02:24:56Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-12-12T02:24:56Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m |  https://beta-dim-learned-hunt.trycloudflare.com                                           |\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 991dffd8889ee9f0147b6b48933da9e4407e68ea8c6d984f55fa2d3db4bb431d)\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 701ddb4c-7823-4f49-945e-4a8e4de580bd\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "2025/12/12 02:24:58 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-12-12T02:24:58Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mfe701123-c2b9-4c13-b8b7-b4a8ee59250a \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27 \u001b[36mlocation=\u001b[0msea01 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.27\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-12-12T02:29:55Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "# Install Streamlit (quiet mode)\n",
        "!pip install -q streamlit\n",
        "\n",
        "# Download Cloudflared (needed to expose Streamlit from Colab)\n",
        "!wget -q -O cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared\n",
        "\n",
        "# Run Streamlit app in the background and log output\n",
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &> /content/streamlit.log &\n",
        "\n",
        "# Create a public tunnel to the Streamlit server\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXfjqkeOcpjg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
